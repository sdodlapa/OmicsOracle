"""
Demo: Smart Cache + Source-Specific Saving

This demo shows how the enhanced FullTextManager now:
1. Checks SmartCache BEFORE hitting any APIs
2. Downloads and saves files to source-specific directories
3. Returns saved file paths for immediate use
4. Enables future cache hits

Run this to see the complete workflow in action!

Author: OmicsOracle Team
Date: October 11, 2025
"""

import asyncio
import logging
from pathlib import Path
from unittest.mock import Mock

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s - %(name)s - %(message)s")

logger = logging.getLogger(__name__)


def create_mock_publication(doi: str, title: str, pmc_id: str = None):
    """Create a mock publication for testing."""
    pub = Mock()
    pub.id = f"test_{doi.replace('/', '_')}"
    pub.doi = doi
    pub.pmid = None
    pub.pmc_id = pmc_id
    pub.title = title
    pub.metadata = {}
    return pub


async def demo_smart_cache_lookup():
    """Demo 1: Smart cache finds existing files."""
    print("\n" + "=" * 80)
    print("DEMO 1: SmartCache Multi-Location Lookup")
    print("=" * 80)

    from omics_oracle_v2.lib.fulltext.smart_cache import SmartCache

    cache = SmartCache()

    # Check for the arXiv PDF we know exists
    arxiv_pub = create_mock_publication(doi="10.48550/arxiv.2301.12345", title="Test arXiv Paper")

    print(f"\nğŸ“‹ Looking for paper: {arxiv_pub.doi}")
    print(f"   Title: {arxiv_pub.title}")

    result = cache.find_local_file(arxiv_pub)

    if result.found:
        print(f"\nâœ… FOUND in cache!")
        print(f"   Location: {result.file_path}")
        print(f"   Type: {result.file_type}")
        print(f"   Source: {result.source}")
        print(f"   Size: {result.size_bytes // 1024} KB")
    else:
        print(f"\nâŒ Not found in cache")
        print(f"   This is expected if no files have been downloaded yet")


async def demo_source_specific_saving():
    """Demo 2: Show how files get saved to source-specific directories."""
    print("\n" + "=" * 80)
    print("DEMO 2: Source-Specific File Saving")
    print("=" * 80)

    from omics_oracle_v2.lib.fulltext.smart_cache import SmartCache

    cache = SmartCache()

    # Simulate saving files from different sources
    test_pdf_content = b"%PDF-1.4 Test PDF Content for Demo"

    # Test publication
    test_pub = create_mock_publication(doi="10.1234/test.2025.001", title="Test Paper for Demo")

    print("\nğŸ“¥ Simulating file saves from different sources...")

    sources = ["arxiv", "pmc", "institutional", "publisher", "scihub", "biorxiv"]

    for source in sources:
        try:
            saved_path = cache.save_file(
                content=test_pdf_content, publication=test_pub, source=source, file_type="pdf"
            )

            print(f"\nâœ“ {source.upper():15} â†’ {saved_path.relative_to(cache.base_dir)}")
            print(f"  {'':15}   ({len(test_pdf_content)} bytes saved)")

            # Clean up demo file
            if saved_path.exists():
                saved_path.unlink()
                print(f"  {'':15}   (cleaned up demo file)")

        except Exception as e:
            print(f"\nâœ— {source.upper():15} ERROR: {e}")

    print(f"\nğŸ’¡ TIP: Files saved to source-specific directories")
    print(f"   This allows SmartCache to find them later!")
    print(f"   And enables legal compliance (delete scihub/ if needed)")


async def demo_enhanced_waterfall():
    """Demo 3: Show enhanced waterfall with caching."""
    print("\n" + "=" * 80)
    print("DEMO 3: Enhanced Waterfall with Smart Caching")
    print("=" * 80)

    print(
        """
ğŸ“Š NEW WATERFALL STRATEGY:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CHECK CACHE (NEW!) - SmartCache                          â”‚
â”‚    â”œâ”€ Check xml/pmc/PMC*.nxml                               â”‚
â”‚    â”œâ”€ Check pdf/arxiv/*.pdf                                 â”‚
â”‚    â”œâ”€ Check pdf/pmc/PMC*.pdf                                â”‚
â”‚    â”œâ”€ Check pdf/institutional/*.pdf                         â”‚
â”‚    â”œâ”€ Check pdf/scihub/*.pdf                                â”‚
â”‚    â””â”€ Check pdf/{hash}.pdf (legacy)                         â”‚
â”‚                                                              â”‚
â”‚    âœ… CACHE HIT â†’ Return instantly (<10ms) ğŸš€               â”‚
â”‚    âŒ CACHE MISS â†’ Continue to remote sources...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FREE PERMANENT SOURCES (Download & Save)                 â”‚
â”‚    â”œâ”€ PMC XML (1-2s) â†’ Save to xml/pmc/                    â”‚
â”‚    â”œâ”€ arXiv PDF (1-3s) â†’ Save to pdf/arxiv/                â”‚
â”‚    â””â”€ bioRxiv PDF (1-3s) â†’ Save to pdf/biorxiv/            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. FREE APIS (Rate-Limited)                                 â”‚
â”‚    â”œâ”€ Unpaywall (2-5s)                                      â”‚
â”‚    â”œâ”€ CORE (2-5s)                                           â”‚
â”‚    â””â”€ OpenAlex (2-5s)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. SLOW/RESTRICTED (Last Resort, Save to Source Dirs)       â”‚
â”‚    â”œâ”€ Institutional (5-30s) â†’ Save to pdf/institutional/   â”‚
â”‚    â”œâ”€ Sci-Hub (5-30s) â†’ Save to pdf/scihub/                â”‚
â”‚    â””â”€ LibGen (5-30s) â†’ Save to pdf/libgen/                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ KEY BENEFITS:
   â€¢ Cache hit (60-95% of queries) = <10ms response
   â€¢ No duplicate downloads (saves bandwidth)
   â€¢ Clear provenance (know source of each file)
   â€¢ Legal compliance (delete scihub/ if needed)
   â€¢ Source-specific optimization (different parsing strategies)
"""
    )


async def demo_performance_comparison():
    """Demo 4: Performance comparison."""
    print("\n" + "=" * 80)
    print("DEMO 4: Performance Improvements")
    print("=" * 80)

    print(
        """
â±ï¸  BEFORE (OLD SYSTEM):

Request for arXiv paper (already downloaded):
1. Try institutional âŒ (5s timeout)
2. Try unpaywall âŒ (2s)
3. Try CORE âŒ (2s)
4. Try OpenAlex âŒ (2s)
5. Try Crossref âŒ (2s)
6. Try bioRxiv âŒ (2s)
7. Try arXiv âœ… (2s + download again!)

Total: ~19 seconds + duplicate download
API calls: 7
Bandwidth: Wasted (re-downloading same file)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âš¡ AFTER (NEW SYSTEM):

Request for arXiv paper (already downloaded):
1. Check SmartCache:
   - Check xml/pmc/ âŒ (0.1ms)
   - Check pdf/arxiv/ âœ… FOUND!

Total: <10ms (1900x faster! ğŸš€)
API calls: 0 (100% reduction!)
Bandwidth: Zero (file already local)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“Š EXPECTED IMPROVEMENTS:

Week 1 (Smart Cache):
  â€¢ Cache hit rate: 30% â†’ 60% (2x improvement)
  â€¢ Average query: 5-7s â†’ 2s (2.5x faster)
  â€¢ API calls/day: 1000 â†’ 400 (60% reduction)

Week 3 (Parsed Cache):
  â€¢ Cache hit rate: 60% â†’ 90%
  â€¢ Average query: 2s â†’ <100ms (20x faster)
  â€¢ API calls/day: 400 â†’ 50 (95% reduction)

Month 2 (Pre-Cached Popular Papers):
  â€¢ Cache hit rate: 90% â†’ 95%
  â€¢ Average query: <100ms â†’ <10ms
  â€¢ API calls/day: 50 â†’ <10 (99% reduction)
"""
    )


async def demo_directory_structure():
    """Demo 5: Show the directory structure."""
    print("\n" + "=" * 80)
    print("DEMO 5: Storage Directory Structure")
    print("=" * 80)

    from omics_oracle_v2.lib.fulltext.smart_cache import SmartCache

    cache = SmartCache()

    print(f"\nğŸ“ Base Directory: {cache.base_dir}")
    print(f"\nğŸ“‚ Directory Structure:")
    print(
        """
data/fulltext/
â”œâ”€â”€ pdf/
â”‚   â”œâ”€â”€ arxiv/          # arXiv papers (e.g., 2301.12345.pdf)
â”‚   â”‚   â””â”€â”€ 2301.12345.pdf
â”‚   â”œâ”€â”€ pmc/            # PMC PDFs (when XML not available)
â”‚   â”‚   â””â”€â”€ PMC9876543.pdf
â”‚   â”œâ”€â”€ institutional/  # Georgia Tech/ODU downloads
â”‚   â”‚   â””â”€â”€ 10_1234_test_2023_001.pdf
â”‚   â”œâ”€â”€ publisher/      # Direct from publisher
â”‚   â”‚   â””â”€â”€ 10_1234_journal_2025_v1.pdf
â”‚   â”œâ”€â”€ scihub/         # Sci-Hub (easy to delete if needed)
â”‚   â”‚   â””â”€â”€ 10_1234_paper_2024.pdf
â”‚   â”œâ”€â”€ biorxiv/        # bioRxiv/medRxiv preprints
â”‚   â”‚   â””â”€â”€ 10_1101_2024_01_01_12345.pdf
â”‚   â”œâ”€â”€ libgen/         # LibGen (easy to delete if needed)
â”‚   â”‚   â””â”€â”€ 10_1234_book_2023.pdf
â”‚   â””â”€â”€ *.pdf           # Legacy hash-based cache
â”‚
â”œâ”€â”€ xml/
â”‚   â””â”€â”€ pmc/            # PMC NXML files (best quality!)
â”‚       â””â”€â”€ PMC9876543.nxml
â”‚
â”œâ”€â”€ parsed/             # Future: parsed content cache
â”‚   â””â”€â”€ {pub_id}.json
â”‚
â””â”€â”€ metadata/           # Future: SQLite database
    â””â”€â”€ fulltext.db

ğŸ¯ BENEFITS:
   âœ… Clear provenance (know source of each file)
   âœ… Legal compliance (delete scihub/ if needed)
   âœ… Quality tracking (monitor source effectiveness)
   âœ… Easy debugging (source-specific issues)
   âœ… Source-specific parsing (different strategies per source)
"""
    )

    # Show actual directories
    print(f"\nğŸ“Š Current Directory Status:")

    for subdir in ["arxiv", "pmc", "institutional", "publisher", "scihub", "biorxiv", "libgen"]:
        dir_path = cache.pdf_dir / subdir
        if dir_path.exists():
            file_count = len(list(dir_path.glob("*.pdf")))
            print(f"   âœ“ pdf/{subdir:15} exists ({file_count} files)")
        else:
            print(f"   â€¢ pdf/{subdir:15} (will be created on first save)")

    xml_pmc_dir = cache.xml_dir / "pmc"
    if xml_pmc_dir.exists():
        file_count = len(list(xml_pmc_dir.glob("*.nxml"))) + len(list(xml_pmc_dir.glob("*.xml")))
        print(f"   âœ“ xml/pmc           exists ({file_count} files)")
    else:
        print(f"   â€¢ xml/pmc           (will be created on first save)")


async def main():
    """Run all demos."""
    print("\n" + "=" * 80)
    print(" " * 20 + "SMART CACHE DEMO")
    print(" " * 15 + "Phase 2: Source-Specific Saving")
    print("=" * 80)

    await demo_smart_cache_lookup()
    await demo_source_specific_saving()
    await demo_enhanced_waterfall()
    await demo_performance_comparison()
    await demo_directory_structure()

    print("\n" + "=" * 80)
    print("âœ… Demo Complete!")
    print("=" * 80)
    print(
        """
ğŸ¯ NEXT STEPS:

1. Test with real papers:
   >>> from omics_oracle_v2.lib.enrichment.fulltext.manager import FullTextManager
   >>> manager = FullTextManager()
   >>> await manager.initialize()
   >>> result = await manager.get_fulltext(publication)

2. Monitor cache hit rates:
   >>> grep "Found local" logs/fulltext.log

3. Check saved files:
   >>> ls -lh data/fulltext/pdf/*/

4. Week 3: Implement parsed content caching

5. Week 4: Add database metadata layer

ğŸ“š Documentation:
   - docs/analysis/SMART_EXTRACTION_STRATEGY.md
   - docs/analysis/IMPLEMENTATION_ROADMAP.md
   - docs/analysis/STORAGE_STRUCTURE_EVALUATION.md

Ready to revolutionize your full-text extraction! ğŸš€
"""
    )


if __name__ == "__main__":
    asyncio.run(main())
