"""
PDF vs PMC XML Comparison Demo

This demonstrates why PMC XML is superior to PDF extraction,
and when you might need PDF extraction anyway.
"""

import xml.etree.ElementTree as ET
from pathlib import Path
import fitz  # PyMuPDF
import pdfplumber


def analyze_pmc_xml():
    """Show what we get from PMC XML (structured, accurate)."""
    print("\n" + "=" * 80)
    print("PMC XML ANALYSIS (Structured, Clean)")
    print("=" * 80)

    xml_file = Path("data/fulltext/xml/pmc/3166277.nxml")
    tree = ET.parse(xml_file)
    root = tree.getroot()

    # Extract structured content
    title = root.find(".//article-title")
    abstract = root.find(".//abstract")
    figures = root.findall(".//fig")
    tables = root.findall(".//table-wrap")
    refs = root.findall(".//ref")

    print(f"\nüìÑ Article: {xml_file.stem}")
    print(f"   Title: {title.text if title is not None else 'N/A'}")
    print(f"   Abstract: {len(abstract.text) if abstract is not None and abstract.text else 0} chars")
    print(f"   Figures: {len(figures)}")
    print(f"   Tables: {len(tables)}")
    print(f"   References: {len(refs)}")

    # Show table structure
    if tables:
        print("\nüìä FIRST TABLE STRUCTURE (from XML):")
        tbl_wrap = tables[0]
        table = tbl_wrap.find(".//table")

        if table is not None:
            rows = table.findall(".//tr")
            print(f"   Total rows: {len(rows)}")

            # First row (headers)
            if rows:
                first_row = rows[0]
                headers = first_row.findall(".//th")
                print(f"   Headers: {[h.text for h in headers if h.text]}")

                # Second row (data)
                if len(rows) > 1:
                    second_row = rows[1]
                    cells = second_row.findall(".//td")
                    print(f"   Sample row: {[c.text for c in cells[:4] if c.text]}")

    # Show figure references
    if figures:
        print("\nüñºÔ∏è  FIGURE REFERENCES (from XML):")
        for i, fig in enumerate(figures[:2], 1):
            label = fig.find(".//label")
            graphic = fig.find(".//graphic")
            caption = fig.find(".//caption")

            print(f"   Figure {i}:")
            print(f"      Label: {label.text if label is not None and label.text else 'N/A'}")
            if graphic is not None:
                href = graphic.get("{http://www.w3.org/1999/xlink}href")
                print(f"      Image file: {href}")
            if caption is not None:
                cap_text = "".join(caption.itertext())
                print(f"      Caption: {cap_text[:100]}...")


def analyze_pdf_with_pymupdf():
    """Show what we can extract from PDF using PyMuPDF."""
    print("\n" + "=" * 80)
    print("PDF ANALYSIS - PyMuPDF (Fast, images+text)")
    print("=" * 80)

    pdf_file = list(Path("data/fulltext/pdf/arxiv").glob("*.pdf"))[0]
    doc = fitz.open(pdf_file)

    print(f"\nüìÑ PDF: {pdf_file.name}")
    print(f"   Pages: {len(doc)}")
    print(f"   Metadata: {doc.metadata.get('title', 'N/A')}")

    # First page analysis
    page = doc[0]
    text = page.get_text()
    images = page.get_images()

    print(f"\nüìù First page:")
    print(f"   Text length: {len(text)} chars")
    print(f"   Text preview: {text[:200].replace(chr(10), ' ')}...")
    print(f"   Images: {len(images)}")

    # Image extraction capability
    total_images = sum(len(p.get_images()) for p in doc)
    print(f"\nüñºÔ∏è  Total images in PDF: {total_images}")
    print(f"   Can extract: ‚úÖ YES (as PNG/JPG)")

    # Table detection (basic - looks for text blocks)
    blocks = page.get_text("dict")["blocks"]
    text_blocks = [b for b in blocks if b["type"] == 0]
    print(f"\nüìä Text blocks (potential tables): {len(text_blocks)}")
    print(f"   Table extraction: ‚ö†Ô∏è  MODERATE (needs manual parsing)")

    doc.close()


def analyze_pdf_with_pdfplumber():
    """Show what we can extract from PDF using pdfplumber (best for tables)."""
    print("\n" + "=" * 80)
    print("PDF ANALYSIS - pdfplumber (Best for tables)")
    print("=" * 80)

    pdf_file = list(Path("data/fulltext/pdf/arxiv").glob("*.pdf"))[0]

    with pdfplumber.open(pdf_file) as pdf:
        print(f"\nüìÑ PDF: {pdf_file.name}")
        print(f"   Pages: {len(pdf.pages)}")

        # First page
        page = pdf.pages[0]
        text = page.extract_text()

        print(f"\nüìù First page:")
        print(f"   Text length: {len(text) if text else 0} chars")

        # Table detection
        tables = page.extract_tables()
        print(f"\nüìä Tables detected: {len(tables)}")

        if tables:
            print(f"   First table rows: {len(tables[0])}")
            print(f"   First table cols: {len(tables[0][0]) if tables[0] else 0}")
            print(f"   Sample row: {tables[0][0][:3] if tables[0] else 'N/A'}")

        # Image detection (metadata only)
        images = page.images
        print(f"\nüñºÔ∏è  Images detected: {len(images)}")
        print(f"   Can extract pixels: ‚ùå NO (metadata only)")


def comparison_summary():
    """Print a comparison summary."""
    print("\n" + "=" * 80)
    print("COMPARISON SUMMARY")
    print("=" * 80)

    comparison = """
Feature                    | PMC XML        | PyMuPDF        | pdfplumber
---------------------------|----------------|----------------|----------------
Text extraction            | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚≠ê‚≠ê‚≠ê‚≠ê Good     | ‚≠ê‚≠ê‚≠ê‚≠ê Good
Structure preservation     | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚≠ê‚≠ê Poor       | ‚≠ê‚≠ê‚≠ê Moderate
Table extraction           | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚≠ê‚≠ê Poor       | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good
Figure captions            | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚ùå None        | ‚ùå None
Image extraction           | ‚≠ê‚≠ê References  | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚ùå Metadata only
References (citations)     | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚≠ê‚≠ê Poor       | ‚≠ê‚≠ê Poor
Author metadata            | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚≠ê‚≠ê Limited    | ‚≠ê‚≠ê Limited
Speed                      | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Instant | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Fast   | ‚≠ê‚≠ê‚≠ê Moderate
Accuracy                   | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Perfect | ‚≠ê‚≠ê‚≠ê Good     | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good

RECOMMENDATION:
1. Use PMC XML when available (90% of recent papers) ‚úÖ
2. Use PyMuPDF for PDF fallback (arXiv, older papers) ‚ö†Ô∏è
3. Use pdfplumber for table extraction from PDFs ‚ö†Ô∏è
4. Consider camelot-py for complex scientific tables ‚ö†Ô∏è

WHY PMC XML WINS:
- Structured by publishers (no parsing errors)
- Includes semantic information (sections, roles, etc.)
- Table structure preserved (rows, columns, headers)
- Citation metadata complete
- No OCR needed
- Faster processing

WHEN YOU NEED PDF EXTRACTION:
- arXiv papers (no PMC XML)
- Publisher PDFs (Elsevier, Springer, Nature, etc.)
- Older papers not in PMC
- Need actual image files (not just references)
- Scanned papers (need OCR)
"""
    print(comparison)


def main():
    """Run all analyses."""
    try:
        analyze_pmc_xml()
        analyze_pdf_with_pymupdf()
        analyze_pdf_with_pdfplumber()
        comparison_summary()

        print("\n" + "=" * 80)
        print("‚úÖ COMPARISON COMPLETE")
        print("=" * 80)
        print("\nCONCLUSION: PMC XML provides superior structured content.")
        print("PDF extraction is needed only when XML unavailable or for images.\n")

    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
