# MiniMax-M2 Integration Strategy Assessment

**Document:** Critical Evaluation of Integration Approaches  
**Date:** November 1, 2025  
**Author:** Technical Architecture Assessment  
**Status:** Strategic Planning

---

## Executive Summary

### Question
Should the new MiniMax-M2 automated genomics data analysis system:
1. **Extend existing dashboard** ("AI Analysis" button)?
2. **Be completely independent** (separate service)?
3. **Utilize/depend on existing query search process**?

### Recommendation: **Hybrid Approach** âœ…

**Extend existing infrastructure while maintaining modularity for independent operation.**

**Rationale:**
- Leverage existing 4-stage pipeline (search â†’ discovery â†’ download â†’ analysis)
- Provide seamless user experience from existing dashboard
- Enable standalone usage for programmatic/API-only access
- Maximize code reuse while avoiding tight coupling
- Future-proof for scaling and service separation

---

## Current Architecture Analysis

### Existing OmicsOracle v2 System

**Entry Point:**
```bash
./start_omics_oracle.sh
â”œâ”€â†’ FastAPI Server (port 8000)
â”œâ”€â†’ HTML Dashboard (/dashboard)
â””â”€â†’ REST API (/api/v2/*)
```

**Current Workflow:**

```
User Query (Dashboard)
    â”‚
    â–¼
POST /api/v2/agents/search
    â”‚
    â”œâ”€â†’ SearchService.execute_search()
    â”‚   â””â”€â†’ SearchOrchestrator
    â”‚       â”œâ”€â†’ GEO Database Search
    â”‚       â”œâ”€â†’ PubMed Citation Discovery
    â”‚       â””â”€â†’ OpenAlex Publication Search
    â”‚
    â””â”€â†’ Returns: SearchResponse
        â”œâ”€ datasets: List[DatasetResponse]
        â””â”€ publications: List[PublicationResponse]
    
    â–¼
POST /api/v2/agents/enrich-fulltext
    â”‚
    â”œâ”€â†’ FulltextService.enrich_datasets()
    â”‚   â””â”€â†’ FullTextManager
    â”‚       â”œâ”€â†’ Download PDFs (PMC, Unpaywall, etc.)
    â”‚       â”œâ”€â†’ Parse text (GROBID, PyMuPDF)
    â”‚       â””â”€â†’ Store in UnifiedDatabase
    â”‚
    â””â”€â†’ Returns: Datasets with fulltext_urls[]
    
    â–¼
POST /api/v2/agents/analyze
    â”‚
    â”œâ”€â†’ AnalysisService.analyze_datasets()
    â”‚   â”œâ”€â†’ Load fulltext from database
    â”‚   â”œâ”€â†’ Build prompts with context
    â”‚   â”œâ”€â†’ Call OpenAI GPT-4
    â”‚   â””â”€â†’ Parse insights/recommendations
    â”‚
    â””â”€â†’ Returns: AIAnalysisResponse
        â”œâ”€ analysis: str (narrative)
        â”œâ”€ insights: List[str]
        â””â”€ recommendations: List[str]
```

**Key Components:**
1. **SearchService**: Finds GEO datasets + publications
2. **FulltextService**: Downloads & parses PDFs
3. **AnalysisService**: GPT-4 text analysis of papers
4. **UnifiedDatabase**: SQLite storage (datasets, publications, fulltext)
5. **Dashboard**: HTML/JS frontend with search + AI analysis

**Current AI Analysis Scope:**
- **Input:** GEO dataset metadata + PDF text from publications
- **Processing:** GPT-4 analyzes PAPERS to explain datasets
- **Output:** Natural language insights about which datasets to use
- **Does NOT:** Download or analyze actual genomics data (FASTQ, counts, etc.)

---

## Proposed M2 System Scope

### What M2 Will Do (NEW Capability)

**Automated Genomics Data Analysis:**

```
Input: GEO ID (e.g., GSE239603)
    â”‚
    â–¼
M2 Data Discovery Agent
    â”œâ”€â†’ Browse GEO web pages
    â”œâ”€â†’ Find FTP data links
    â”œâ”€â†’ Identify file types (counts, FASTQ, CEL)
    â””â”€â†’ Return: List[DataFile] with URLs
    
    â–¼
M2 Code Generator Agent
    â”œâ”€â†’ Generate Python pipeline:
    â”‚   â”œâ”€ FTP download code
    â”‚   â”œâ”€ Data preprocessing
    â”‚   â”œâ”€ Statistical analysis (DE, GO, etc.)
    â”‚   â””â”€ Visualization code
    â””â”€â†’ Return: Complete executable Python code
    
    â–¼
Code Safety Validator
    â”œâ”€â†’ AST parsing for dangerous patterns
    â”œâ”€â†’ Network whitelist check
    â””â”€â†’ If safe â†’ proceed, else reject
    
    â–¼
Docker Sandbox Executor
    â”œâ”€â†’ Create isolated container
    â”œâ”€â†’ Install dependencies
    â”œâ”€â†’ Execute generated code
    â”œâ”€â†’ Monitor resources
    â””â”€â†’ Capture outputs (plots, CSV)
    
    â–¼
Results Package
    â”œâ”€â†’ Generated plots (volcano, heatmap, PCA)
    â”œâ”€â†’ Statistical results (CSV)
    â”œâ”€â†’ Reproducible code
    â””â”€â†’ Natural language report
```

**Key Difference:**
- **Current AI Analysis:** Reads PAPERS about datasets
- **Proposed M2 System:** Downloads & analyzes actual GENOMICS DATA

---

## Integration Strategy Options

### Option 1: Extend Existing Dashboard âœ… (RECOMMENDED)

**Architecture:**

```
Dashboard (dashboard_v2.html)
    â”‚
    â”œâ”€â†’ [Existing] "Search" â†’ /api/v2/agents/search
    â”‚
    â”œâ”€â†’ [Existing] "AI Analysis" â†’ /api/v2/agents/analyze
    â”‚       (GPT-4 analyzes papers about datasets)
    â”‚
    â””â”€â†’ [NEW] "Automated Data Analysis" â†’ /api/v3/agent/analyze-geo
            (M2 downloads & analyzes actual genomics data)
```

**Implementation:**

```javascript
// dashboard_v2.html - Add new button

// Existing AI Analysis button (keep as-is)
<button onclick="analyzeDatasets()">
    AI Analysis (Papers)
</button>

// NEW Automated Data Analysis button
<button onclick="automatedGEOAnalysis()">
    ğŸ¤– Automated Data Analysis (M2)
</button>

async function automatedGEOAnalysis() {
    const selectedDataset = getSelectedDataset(); // User picks one dataset
    
    const response = await fetch('/api/v3/agent/analyze-geo', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
            geo_id: selectedDataset.geo_id,
            analysis_type: 'differential_expression',
            query: 'Compare conditions in this dataset',
            parameters: {
                padj_threshold: 0.05,
                log2fc_threshold: 1.0
            }
        })
    });
    
    const result = await response.json();
    // Poll /api/v3/agent/status/{analysis_id} for progress
    // Display results when complete
}
```

**Pros:**
- âœ… **Seamless UX**: Users discover datasets â†’ click "Automated Analysis" â†’ get results
- âœ… **Leverage existing search**: Reuse SearchService to find GEO datasets
- âœ… **Natural workflow**: Search â†’ Select â†’ Analyze (one interface)
- âœ… **Shared infrastructure**: Same database, cache, auth
- âœ… **Easier onboarding**: Users already familiar with dashboard

**Cons:**
- âš ï¸ **Risk of tight coupling**: Must maintain clean separation
- âš ï¸ **Increased complexity**: Dashboard now has two "analysis" features
- âš ï¸ **Performance impact**: Heavy M2 tasks on same server

**Mitigation:**
```python
# Use FastAPI BackgroundTasks to offload M2 processing
@router.post("/api/v3/agent/analyze-geo")
async def start_m2_analysis(request, background_tasks: BackgroundTasks):
    analysis_id = create_analysis_job()
    background_tasks.add_task(execute_m2_pipeline, analysis_id, request)
    return {"analysis_id": analysis_id, "status": "queued"}
```

---

### Option 2: Completely Independent Service âŒ (NOT RECOMMENDED)

**Architecture:**

```
Two Separate Services:

Service 1: OmicsOracle v2 (Existing)
    - Port 8000
    - Dashboard: /dashboard
    - API: /api/v2/*
    - Searches GEO + analyzes papers

Service 2: M2 Analysis Service (New)
    - Port 9000
    - Dashboard: /m2-dashboard
    - API: /api/m2/*
    - Analyzes genomics data
```

**Pros:**
- âœ… **Complete isolation**: No risk of breaking existing system
- âœ… **Independent scaling**: Can scale M2 service separately
- âœ… **Clear separation**: Different teams can maintain each service

**Cons:**
- âŒ **Fragmented UX**: Users must use two different dashboards
- âŒ **Code duplication**: Duplicate GEO metadata fetch, auth, caching
- âŒ **Data redundancy**: Separate databases for datasets
- âŒ **Harder to discover**: Users may not know M2 service exists
- âŒ **Integration overhead**: If later need to connect them, major refactor

**Verdict:** âŒ Rejected - Poor user experience, unnecessary complexity

---

### Option 3: Hybrid (Modular Integration) âœ…âœ… (BEST APPROACH)

**Architecture:**

```
OmicsOracle v3 Unified System
â”‚
â”œâ”€ FastAPI Server (main.py)
â”‚   â”œâ”€ API v2 routes (existing)
â”‚   â”‚   â”œâ”€ /api/v2/agents/search
â”‚   â”‚   â”œâ”€ /api/v2/agents/enrich-fulltext
â”‚   â”‚   â””â”€ /api/v2/agents/analyze (paper analysis)
â”‚   â”‚
â”‚   â””â”€ API v3 routes (new M2 routes)
â”‚       â”œâ”€ /api/v3/agent/analyze-geo (M2 data analysis)
â”‚       â”œâ”€ /api/v3/agent/status/{id}
â”‚       â””â”€ /api/v3/agent/results/{id}
â”‚
â”œâ”€ Services Layer (reusable across v2/v3)
â”‚   â”œâ”€ SearchService (shared)
â”‚   â”œâ”€ FulltextService (shared)
â”‚   â”œâ”€ AnalysisService (v2 - paper analysis)
â”‚   â””â”€ M2AnalysisService (v3 - data analysis) â† NEW
â”‚       â”œâ”€ M2Orchestrator
â”‚       â”œâ”€ DataDiscoveryAgent
â”‚       â”œâ”€ CodeGeneratorAgent
â”‚       â”œâ”€ ExecutionSandbox
â”‚       â””â”€ ErrorRecoveryAgent
â”‚
â”œâ”€ Database Layer (shared)
â”‚   â”œâ”€ UnifiedDatabase (existing)
â”‚   â””â”€ Add new tables:
â”‚       â”œâ”€ m2_analyses (job tracking)
â”‚       â”œâ”€ m2_results (DE results, etc.)
â”‚       â””â”€ code_cache (successful pipelines)
â”‚
â””â”€ Dashboard (single unified UI)
    â”œâ”€ Search Tab (existing)
    â”œâ”€ AI Analysis Tab (existing - paper analysis)
    â””â”€ Data Analysis Tab (new - M2 genomics analysis)
```

**Service Isolation via Dependency Injection:**

```python
# omics_oracle_v2/services/m2_analysis_service.py

class M2AnalysisService:
    """
    M2-powered genomics data analysis service.
    
    Designed for:
    - Dashboard integration (called from UI)
    - Standalone API usage (programmatic access)
    - Microservice deployment (can be extracted later)
    """
    
    def __init__(
        self,
        search_service: Optional[SearchService] = None,  # Inject existing service
        db: Optional[UnifiedDatabase] = None,            # Share database
        m2_config: Optional[M2Config] = None             # Independent config
    ):
        # Use injected services if available, else create new
        self.search_service = search_service or SearchService()
        self.db = db or UnifiedDatabase()
        self.m2_config = m2_config or M2Config.from_env()
        
        # M2-specific components (isolated)
        self.m2_orchestrator = MiniMaxM2Orchestrator(self.m2_config)
        self.sandbox = ExecutionSandbox()
        self.validator = CodeSafetyValidator()
    
    async def analyze_geo_dataset(
        self,
        geo_id: str,
        analysis_type: str,
        query: str
    ) -> AnalysisResult:
        """
        Full M2 analysis pipeline.
        
        Can optionally use SearchService to fetch GEO metadata,
        or fetch directly if standalone.
        """
        # Option 1: Use existing service (if integrated)
        if self.search_service:
            metadata = await self.search_service.get_geo_metadata(geo_id)
        # Option 2: Fetch directly (if standalone)
        else:
            metadata = await self._fetch_geo_metadata_directly(geo_id)
        
        # Rest of M2 pipeline...
        # (independent of how metadata was obtained)
```

**Dashboard Integration:**

```javascript
// dashboard_v2.html - Unified interface with tabs

<div class="tabs">
    <button class="tab active" data-tab="search">
        ğŸ” Search Datasets
    </button>
    <button class="tab" data-tab="ai-analysis">
        ğŸ“„ AI Analysis (Papers)
    </button>
    <button class="tab" data-tab="data-analysis">
        ğŸ¤– Data Analysis (M2) <span class="badge">NEW</span>
    </button>
</div>

<div id="data-analysis-tab" class="tab-content">
    <h3>Automated Genomics Data Analysis</h3>
    <p>Let AI download and analyze your data automatically</p>
    
    <!-- User selects dataset from search results -->
    <select id="dataset-select">
        <option>GSE239603 - APOE4 microglia</option>
    </select>
    
    <!-- Analysis type -->
    <select id="analysis-type">
        <option value="differential_expression">Differential Expression</option>
        <option value="gene_ontology">Gene Ontology</option>
        <option value="clustering">Clustering</option>
    </select>
    
    <!-- Natural language query -->
    <input type="text" placeholder="E.g., Compare APOE4 vs control" />
    
    <button onclick="runM2Analysis()">
        ğŸš€ Run Automated Analysis
    </button>
    
    <!-- Progress indicator -->
    <div id="m2-progress" style="display:none">
        <div class="progress-bar">
            <div class="progress-fill" style="width: 45%"></div>
        </div>
        <p>Executing analysis code... (45%)</p>
        <button onclick="cancelAnalysis()">Cancel</button>
    </div>
    
    <!-- Results display -->
    <div id="m2-results" style="display:none">
        <h4>Analysis Complete! âœ…</h4>
        <div class="result-summary">
            <p>Found 2,489 differentially expressed genes</p>
            <p>Execution time: 4 minutes 5 seconds</p>
        </div>
        
        <div class="result-plots">
            <img src="/results/{id}/volcano.png" />
            <img src="/results/{id}/heatmap.png" />
        </div>
        
        <div class="downloads">
            <a href="/results/{id}/results.csv">ğŸ“Š Download Results CSV</a>
            <a href="/results/{id}/code.py">ğŸ’» View Generated Code</a>
            <a href="/results/{id}/report.md">ğŸ“„ Analysis Report</a>
        </div>
    </div>
</div>
```

**Pros:**
- âœ… **Best UX**: Single dashboard, natural workflow
- âœ… **Code reuse**: Share SearchService, database, auth
- âœ… **Modularity**: M2 service can be extracted later if needed
- âœ… **Clear boundaries**: v2 = paper analysis, v3 = data analysis
- âœ… **Future-proof**: Easy to separate into microservices later
- âœ… **Backward compatible**: Doesn't break existing API

**Cons:**
- âš ï¸ **Initial complexity**: Need careful API design to avoid coupling
- âš ï¸ **Resource contention**: M2 uses GPUs, may impact API performance

**Mitigation:**
```python
# Option 1: Background processing (keeps API responsive)
@router.post("/api/v3/agent/analyze-geo")
async def start_analysis(request, background_tasks):
    analysis_id = uuid4()
    background_tasks.add_task(m2_service.analyze_geo_dataset, analysis_id, request)
    return {"analysis_id": analysis_id, "status_url": f"/api/v3/agent/status/{analysis_id}"}

# Option 2: Separate worker processes (recommended for production)
# Use Celery or FastAPI BackgroundTasks with worker pool
# Workers run on GPU nodes, API stays lightweight
```

---

## Dependency Strategy

### What to Reuse from Existing System

**âœ… REUSE:**

1. **SearchService** (find GEO datasets)
   - M2 needs GEO ID â†’ Use existing search to validate/fetch metadata
   - Avoid re-implementing GEO API calls

2. **UnifiedDatabase** (store results)
   - Add M2-specific tables alongside existing ones
   - Share transaction management, connection pooling

3. **Authentication & Authorization**
   - Same user accounts, tokens, permissions
   - Rate limiting applies to both v2 and v3 APIs

4. **Caching (Redis)**
   - Cache M2 analysis results (expensive!)
   - Share cache infrastructure, different key prefixes

5. **Logging & Monitoring**
   - Same Prometheus metrics, Grafana dashboards
   - Unified observability

**âŒ DO NOT REUSE:**

1. **AnalysisService** (GPT-4 paper analysis)
   - Different purpose, different LLM
   - Keep separate to avoid confusion

2. **FulltextService** (PDF download)
   - M2 doesn't need PDFs (downloads data files instead)
   - Can share some HTTP client utilities, but not core logic

3. **Dashboard JavaScript** (existing AI Analysis code)
   - Write new M2-specific UI components
   - Avoid cluttering existing code

---

## Implementation Phases

### Phase 1: Minimal Integration (Weeks 1-2)

**Goal:** M2 accessible via API, triggered manually from dashboard

```python
# Add to existing FastAPI app
from omics_oracle_v2.api.routes import agent_analysis_v3

app.include_router(
    agent_analysis_v3.router,
    prefix="/api/v3/agent",
    tags=["Agent Analysis v3"]
)
```

**Dashboard Changes:**
- Add "Data Analysis (Beta)" button
- Clicking opens modal with GEO ID input
- Calls `/api/v3/agent/analyze-geo`
- Polls for status, displays results when ready

**No changes to existing features!**

### Phase 2: Workflow Integration (Weeks 3-4)

**Goal:** Seamless flow from search â†’ select â†’ analyze

```javascript
// In search results display
datasets.forEach(dataset => {
    // Existing: "AI Analysis" (paper analysis)
    addButton(dataset, "AI Analysis", analyzePapers);
    
    // NEW: "Run Data Analysis" (M2 genomics analysis)
    addButton(dataset, "ğŸ¤– Analyze Data", runM2Analysis);
});
```

**User Flow:**
1. Search: "Alzheimer's disease microglia"
2. See results: GSE239603, GSE180759, ...
3. Click "ğŸ¤– Analyze Data" on GSE239603
4. M2 automatically:
   - Discovers data files
   - Generates analysis code
   - Executes in sandbox
   - Shows volcano plot, heatmap, results

### Phase 3: Advanced Features (Weeks 5-8)

- **Batch analysis**: Analyze multiple datasets in parallel
- **Custom parameters**: User sets p-value thresholds, etc.
- **Analysis templates**: Pre-configured workflows (DE, GO, PCA)
- **Results comparison**: Compare analyses across datasets
- **Code export**: Users can download & run code locally

---

## Resource Allocation

### Computational Resources

**Current System:**
- **API Server:** Lightweight (2 CPU cores, 4GB RAM)
- **Database:** SQLite (local file)
- **Cache:** Redis (512MB)

**M2 System Requirements:**
- **M2 Inference:** 4Ã— H100 GPUs, 256GB RAM, 48 CPU cores
- **Worker Nodes:** 8 cores, 32GB RAM each (for sandbox execution)

**Deployment Strategy:**

```yaml
# Kubernetes deployment

# Node 1: API + Dashboard (existing, lightweight)
api-server:
  replicas: 2
  resources:
    cpu: 2
    memory: 4Gi

# Node 2: M2 Inference (NEW, GPU node)
m2-inference:
  replicas: 1
  resources:
    gpu: 4  # H100
    cpu: 48
    memory: 256Gi

# Node 3-6: Worker Pool (NEW, CPU nodes)
m2-workers:
  replicas: 4
  resources:
    cpu: 8
    memory: 32Gi
```

**Communication:**
```
API Server (Port 8000)
    â”‚
    â”œâ”€â†’ HTTP â†’ M2 Inference (Port 8080)
    â””â”€â†’ Queue â†’ Worker Pool (via Redis)
```

**Benefits:**
- API stays responsive (no GPU blocking)
- M2 can scale independently
- Workers can scale based on queue depth

---

## Risk Analysis

### Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **M2 service crashes API** | HIGH | LOW | Run M2 in separate process/container |
| **GPU resource exhaustion** | MEDIUM | MEDIUM | Queue system, max concurrent limit |
| **Generated code hangs** | MEDIUM | HIGH | Execution timeout (30 min), monitoring |
| **Security breach via code** | CRITICAL | LOW | Multi-layer validation, sandboxing |
| **Database lock contention** | MEDIUM | LOW | Use async I/O, consider PostgreSQL |
| **User confusion (2 analysis types)** | MEDIUM | MEDIUM | Clear UI labels, tooltips, examples |

### User Experience Risks

| Risk | Mitigation |
|------|------------|
| "Why do I need two analysis buttons?" | Clear tooltips: "AI Analysis = papers, Data Analysis = actual data" |
| "Data analysis failed, why?" | Detailed error messages, link to docs |
| "Results take too long" | Progress bar, email notification, estimated time |
| "I don't understand the code" | Generated report explains in plain English |

---

## Decision Matrix

| Criterion | Extend Dashboard | Independent Service | Hybrid (Recommended) |
|-----------|-----------------|---------------------|---------------------|
| **User Experience** | â­â­â­â­â­ Excellent | â­â­ Poor | â­â­â­â­â­ Excellent |
| **Code Reuse** | â­â­â­â­ Good | â­ Poor | â­â­â­â­â­ Excellent |
| **Modularity** | â­â­â­ Moderate | â­â­â­â­â­ Excellent | â­â­â­â­ Good |
| **Scalability** | â­â­â­ Moderate | â­â­â­â­â­ Excellent | â­â­â­â­ Good |
| **Development Speed** | â­â­â­â­ Fast | â­â­ Slow | â­â­â­â­ Fast |
| **Maintenance Burden** | â­â­â­ Moderate | â­â­ High | â­â­â­â­ Good |
| **Future-Proofing** | â­â­â­ Moderate | â­â­â­â­ Good | â­â­â­â­â­ Excellent |
| **Risk** | â­â­â­ Medium | â­â­â­â­ Low | â­â­â­â­ Low |
| **Overall Score** | 27/40 | 26/40 | **35/40** âœ… |

---

## Final Recommendation

### Adopt Hybrid Approach with Phased Implementation

**Implementation Strategy:**

```
Phase 1 (Weeks 1-4): Modular Backend
â”œâ”€ Create M2AnalysisService (independent module)
â”œâ”€ Add /api/v3/agent/* routes (new API version)
â”œâ”€ Share SearchService & UnifiedDatabase (dependency injection)
â””â”€ No dashboard changes yet (API-only testing)

Phase 2 (Weeks 5-8): Dashboard Integration
â”œâ”€ Add "Data Analysis" tab to existing dashboard
â”œâ”€ Wire up to /api/v3/agent/analyze-geo endpoint
â”œâ”€ Add progress tracking & results display
â””â”€ User testing & feedback

Phase 3 (Weeks 9-12): Production Hardening
â”œâ”€ Deploy M2 on separate GPU nodes
â”œâ”€ Set up worker pool for sandbox execution
â”œâ”€ Add monitoring, alerting, logging
â””â”€ Launch to users

Phase 4 (Months 4-6): Optimization
â”œâ”€ Caching for expensive analyses
â”œâ”€ Batch processing
â”œâ”€ Advanced features (custom workflows)
â””â”€ Consider microservice extraction if needed
```

**Why This Works:**

1. âœ… **Immediate value**: Users get M2 analysis without switching tools
2. âœ… **Low risk**: M2 runs in isolation, can't break existing features
3. âœ… **Flexible**: Can extract to microservice later if needed
4. âœ… **Cost-efficient**: Share infrastructure where possible
5. âœ… **User-friendly**: Single dashboard, intuitive workflow

**Key Principles:**

- **Loose coupling**: M2 service can run standalone if needed
- **High cohesion**: Related features (search + analysis) in one place
- **Progressive enhancement**: Add M2 without breaking existing functionality
- **Service-oriented**: Design for future microservice architecture

---

## Conclusion

**The M2 genomics data analysis system should be integrated into the existing OmicsOracle dashboard as a new capability, while maintaining clean architectural boundaries that allow for future service separation.**

This approach provides the best user experience, maximizes code reuse, and positions the system for future scaling and evolution.

**Next Steps:**
1. Review this assessment with stakeholders
2. Approve hybrid integration approach
3. Begin Phase 1 implementation (modular backend)
4. Prepare dashboard mockups for Phase 2

---

**Document Status:** âœ… Ready for Review  
**Approval Required From:** Technical Lead, Product Manager  
**Estimated Implementation:** 12 weeks to production
