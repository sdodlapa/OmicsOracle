# Pipeline Separation - Visual Guide

**Date**: October 14, 2025

---

## Current State (Tightly Coupled)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  lib/enrichment/fulltext/  (ALL MIXED TOGETHER)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  manager.py (1,323 lines) âš ï¸ DOES EVERYTHING               â”‚
â”‚  â”œâ”€ URL Collection (Pipeline 2) âœ…                          â”‚
â”‚  â”œâ”€ PDF Download (Pipeline 3) âš ï¸ Shouldn't be here        â”‚
â”‚  â””â”€ Text Parsing (Pipeline 4) âš ï¸ Shouldn't be here        â”‚
â”‚                                                             â”‚
â”‚  download_manager.py (543 lines) âœ… CLEAN                   â”‚
â”‚  â””â”€ PDF Download (Pipeline 3) âœ…                            â”‚
â”‚                                                             â”‚
â”‚  pdf_parser.py (46 lines) âš ï¸ INCOMPLETE                     â”‚
â”‚  â””â”€ Text Parsing (Pipeline 4) âš ï¸ Only 10% done             â”‚
â”‚                                                             â”‚
â”‚  sources/ (11 source clients)                              â”‚
â”‚  â””â”€ Used by Pipeline 2 âœ…                                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problems:
âŒ Can't test pipelines independently
âŒ Changes ripple across pipelines
âŒ Pipeline 4 incomplete and trapped
âŒ Unclear responsibilities
```

---

## Proposed State (Clean Separation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  lib/pipelines/                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 1_citation_discovery/  âœ… ALREADY ORGANIZED        â”‚     â”‚
â”‚  â”‚ â””â”€ Pipeline 1: GEO â†’ Papers                        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                    [List[Publication]]                       â”‚
â”‚                              â”‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 2_url_collection/  ğŸ†• MOVE FROM enrichment/        â”‚     â”‚
â”‚  â”‚ â”œâ”€ manager.py (URL collection only)                â”‚     â”‚
â”‚  â”‚ â”œâ”€ sources/ (11 sources)                           â”‚     â”‚
â”‚  â”‚ â””â”€ models.py (FullTextResult)                      â”‚     â”‚
â”‚  â”‚                                                     â”‚     â”‚
â”‚  â”‚ INPUT:  List[Publication]                          â”‚     â”‚
â”‚  â”‚ OUTPUT: List[FullTextResult]                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                  [List[FullTextResult]]                      â”‚
â”‚                              â”‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 3_pdf_download/  ğŸ†• MOVE FROM enrichment/          â”‚     â”‚
â”‚  â”‚ â”œâ”€ manager.py (PDFDownloadManager)                 â”‚     â”‚
â”‚  â”‚ â”œâ”€ utils/ (landing_page_parser)                    â”‚     â”‚
â”‚  â”‚ â””â”€ models.py (DownloadResult)                      â”‚     â”‚
â”‚  â”‚                                                     â”‚     â”‚
â”‚  â”‚ INPUT:  List[FullTextResult]                       â”‚     â”‚
â”‚  â”‚ OUTPUT: List[DownloadResult]                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                  [List[DownloadResult]]                      â”‚
â”‚                              â”‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 4_text_enrichment/  ğŸ†• IMPLEMENT (was incomplete)  â”‚     â”‚
â”‚  â”‚ â”œâ”€ manager.py (TextEnrichmentManager)              â”‚     â”‚
â”‚  â”‚ â”œâ”€ extractors/                                     â”‚     â”‚
â”‚  â”‚ â”‚   â”œâ”€ grobid_client.py (GROBID integration) ğŸ†•    â”‚     â”‚
â”‚  â”‚ â”‚   â”œâ”€ pypdf_extractor.py (current)               â”‚     â”‚
â”‚  â”‚ â”‚   â””â”€ pdfminer_extractor.py (fallback) ğŸ†•        â”‚     â”‚
â”‚  â”‚ â”œâ”€ enrichers/                                      â”‚     â”‚
â”‚  â”‚ â”‚   â”œâ”€ section_detector.py ğŸ†•                      â”‚     â”‚
â”‚  â”‚ â”‚   â”œâ”€ table_extractor.py ğŸ†•                       â”‚     â”‚
â”‚  â”‚ â”‚   â””â”€ normalizer.py                               â”‚     â”‚
â”‚  â”‚ â”œâ”€ formatters/                                     â”‚     â”‚
â”‚  â”‚ â”‚   â””â”€ chatgpt_formatter.py ğŸ†•                     â”‚     â”‚
â”‚  â”‚ â””â”€ models.py (EnrichmentResult, ParsedContent)     â”‚     â”‚
â”‚  â”‚                                                     â”‚     â”‚
â”‚  â”‚ INPUT:  List[DownloadResult]                       â”‚     â”‚
â”‚  â”‚ OUTPUT: List[EnrichmentResult]                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                  [List[EnrichmentResult]]                    â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                         ChatGPT âœ…                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
âœ… Each pipeline testable independently
âœ… Clear input/output contracts
âœ… Single responsibility per pipeline
âœ… Easy to add features to specific pipeline
âœ… Pipeline 4 fully implemented
```

---

## Data Flow Comparison

### Current (Mixed)

```
Publication
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FullTextManager                 â”‚
â”‚ .get_parsed_content()           â”‚
â”‚                                 â”‚
â”‚ âš ï¸ DOES EVERYTHING:             â”‚
â”‚  1. Collect URLs                â”‚
â”‚  2. Download PDF                â”‚
â”‚  3. Parse PDF                   â”‚
â”‚  4. Return text                 â”‚
â”‚                                 â”‚
â”‚ Problem: Can't test stages     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Dict[str, any]
```

### Proposed (Separated)

```
Publication
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline 2: URLCollectionManagerâ”‚
â”‚ .collect_urls_batch()           â”‚
â”‚                                 â”‚
â”‚ âœ… ONLY collects URLs           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
FullTextResult (with all_urls)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline 3: PDFDownloadManager  â”‚
â”‚ .download_batch()               â”‚
â”‚                                 â”‚
â”‚ âœ… ONLY downloads PDFs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
DownloadResult (with pdf_path)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline 4: TextEnrichmentMgr   â”‚
â”‚ .enrich_batch()                 â”‚
â”‚                                 â”‚
â”‚ âœ… ONLY parses & enriches text  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
EnrichmentResult (with structured content)
```

---

## Integration Contracts

### Contract 1â†’2: Publication â†’ FullTextResult

```python
# INPUT (from Pipeline 1)
@dataclass
class Publication:
    title: str
    doi: Optional[str]
    pmid: Optional[str]
    pmcid: Optional[str]
    # ... other metadata

# OUTPUT (from Pipeline 2)
@dataclass
class FullTextResult:
    success: bool
    publication: Publication    # Original
    url: Optional[str]          # Best URL
    all_urls: List[SourceURL]   # All URLs (for fallback)
    source: Optional[str]
    error: Optional[str]
```

**Integration Point**:
```python
results = await url_collector.collect_urls_batch(publications)
```

---

### Contract 2â†’3: FullTextResult â†’ DownloadResult

```python
# INPUT (from Pipeline 2)
@dataclass
class FullTextResult:
    all_urls: List[SourceURL]   # URLs to try
    publication: Publication

# OUTPUT (from Pipeline 3)
@dataclass
class DownloadResult:
    success: bool
    publication: Publication    # Original
    pdf_path: Optional[Path]    # Downloaded file
    source: Optional[str]       # Which URL worked
    file_size: int
    error: Optional[str]
```

**Integration Point**:
```python
download_results = await pdf_downloader.download_batch(
    fulltext_results,
    output_dir
)
```

---

### Contract 3â†’4: DownloadResult â†’ EnrichmentResult

```python
# INPUT (from Pipeline 3)
@dataclass
class DownloadResult:
    pdf_path: Optional[Path]    # PDF to parse
    publication: Publication

# OUTPUT (from Pipeline 4)
@dataclass
class EnrichmentResult:
    success: bool
    publication: Publication    # Original
    pdf_path: Path             # Input PDF
    content: Optional[ParsedContent]  # Structured content
    chatgpt_ready: Optional[Dict]     # LLM-formatted
    error: Optional[str]

@dataclass
class ParsedContent:
    full_text: str
    sections: Dict[str, str]    # {section_name: text}
    tables: List[Dict]          # Extracted tables
    figures: List[Dict]         # Figure captions
    references: List[str]
    metadata: Dict
    extraction_method: str      # "grobid", "pypdf"
    quality_score: float        # 0.0-1.0
```

**Integration Point**:
```python
enrichment_results = await text_enricher.enrich_batch(
    download_results,
    include_chatgpt_format=True
)
```

---

## File Count Comparison

### Current Structure

```
lib/enrichment/fulltext/
â”œâ”€â”€ manager.py                    # 1 file (1,323 lines - does too much)
â”œâ”€â”€ download_manager.py           # 1 file (543 lines)
â”œâ”€â”€ pdf_parser.py                 # 1 file (46 lines - incomplete)
â”œâ”€â”€ sources/                      # 11 files
â”œâ”€â”€ utils/                        # 2 files
â””â”€â”€ support/                      # 7 files
                                  â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 23 files, ~3,500 lines
```

### Proposed Structure

```
lib/pipelines/
â”œâ”€â”€ 2_url_collection/
â”‚   â”œâ”€â”€ manager.py                # 1 file (~600 lines - URL only)
â”‚   â”œâ”€â”€ config.py                 # 1 file
â”‚   â”œâ”€â”€ models.py                 # 1 file
â”‚   â””â”€â”€ sources/                  # 11 files
â”‚
â”œâ”€â”€ 3_pdf_download/
â”‚   â”œâ”€â”€ manager.py                # 1 file (543 lines)
â”‚   â”œâ”€â”€ config.py                 # 1 file
â”‚   â”œâ”€â”€ models.py                 # 1 file
â”‚   â””â”€â”€ utils/                    # 2 files
â”‚
â””â”€â”€ 4_text_enrichment/
    â”œâ”€â”€ manager.py                # 1 file (~400 lines - NEW)
    â”œâ”€â”€ config.py                 # 1 file
    â”œâ”€â”€ models.py                 # 1 file
    â”œâ”€â”€ extractors/               # 3 files (GROBID, pypdf, pdfminer)
    â”œâ”€â”€ enrichers/                # 3 files (sections, tables, normalizer)
    â””â”€â”€ formatters/               # 1 file (ChatGPT formatter)

lib/shared/                       # Shared utilities
â”œâ”€â”€ cache/                        # 3 files
â”œâ”€â”€ validators/                   # 2 files
â””â”€â”€ utils/                        # 2 files
                                  â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~40 files, ~5,000 lines
(More files but better organized, +1,500 lines for Pipeline 4)
```

---

## Testing Strategy

### Current (Hard to Test)

```python
# Must mock 11 sources + HTTP + file system
@pytest.mark.asyncio
async def test_get_parsed_content():
    manager = FullTextManager()
    
    # âš ï¸ Mocks required:
    # - 11 URL sources
    # - HTTP downloader
    # - File system
    # - PDF parser
    
    result = await manager.get_parsed_content(pub)
    
    # âš ï¸ What failed? URL? Download? Parse?
    assert result is not None
```

---

### Proposed (Easy to Test)

```python
# Test Pipeline 2 alone
@pytest.mark.asyncio
async def test_url_collection():
    manager = URLCollectionManager()
    
    # Mock only URL sources
    with patch.object(manager, '_try_pmc', return_value=mock_result):
        results = await manager.collect_urls_batch([pub])
    
    assert isinstance(results[0], FullTextResult)
    assert results[0].success


# Test Pipeline 3 alone
@pytest.mark.asyncio
async def test_pdf_download():
    manager = PDFDownloadManager()
    
    # Mock only HTTP
    with aioresponses() as mocked:
        mocked.get('http://example.com/paper.pdf', body=mock_pdf_bytes)
        
        results = await manager.download_batch(fulltext_results, output_dir)
    
    assert isinstance(results[0], DownloadResult)
    assert results[0].pdf_path.exists()


# Test Pipeline 4 alone
@pytest.mark.asyncio
async def test_text_enrichment():
    manager = TextEnrichmentManager()
    
    # Mock only GROBID client
    with patch.object(manager.grobid_client, 'process', return_value=mock_xml):
        results = await manager.enrich_batch(download_results)
    
    assert isinstance(results[0], EnrichmentResult)
    assert 'Introduction' in results[0].content.sections
```

---

## Migration Timeline

```
Week 1-2: Pipeline 2 Extraction
â”œâ”€ Create lib/pipelines/2_url_collection/
â”œâ”€ Move manager.py + sources/
â”œâ”€ Remove download/parse from manager
â”œâ”€ Update all imports
â””â”€ Create tests
    â”‚
    â–¼
Week 2-3: Pipeline 3 Extraction
â”œâ”€ Create lib/pipelines/3_pdf_download/
â”œâ”€ Move download_manager.py
â”œâ”€ Update API to accept FullTextResult
â”œâ”€ Update imports
â””â”€ Create tests
    â”‚
    â–¼
Week 3-5: Pipeline 4 Implementation
â”œâ”€ Create lib/pipelines/4_text_enrichment/
â”œâ”€ Deploy GROBID service (Docker)
â”œâ”€ Implement GROBID client
â”œâ”€ Implement section detection
â”œâ”€ Implement table extraction
â”œâ”€ Implement ChatGPT formatter
â”œâ”€ Create manager
â””â”€ Create tests
    â”‚
    â–¼
Week 5-6: Integration & Testing
â”œâ”€ Create end-to-end tests
â”œâ”€ Update API to use separated pipelines
â”œâ”€ Performance benchmarking
â”œâ”€ Documentation
â””â”€ Deployment
```

---

## Success Metrics

### Before Separation
- âŒ 1 monolithic manager (1,323 lines)
- âŒ Pipelines can't be tested independently
- âŒ Pipeline 4 only 10% complete
- âŒ Changes to one pipeline affect others
- âŒ Hard to understand data flow

### After Separation
- âœ… 4 independent pipelines
- âœ… Each pipeline fully testable
- âœ… Pipeline 4 100% complete
- âœ… Clear boundaries and contracts
- âœ… Easy to understand and maintain
- âœ… Ready for ChatGPT integration

---

## Risk Assessment

### Low Risk âœ…
- Pipeline 3 already clean (easy move)
- Clear contracts defined
- Phased rollout possible

### Medium Risk âš ï¸
- Pipeline 2 needs refactoring (remove download/parse)
- Many import updates needed
- Integration testing required

### High Risk (Mitigated) ğŸ”´â†’âœ…
- Pipeline 4 GROBID implementation (NEW)
- **Mitigation**: Start with pypdf, add GROBID incrementally
- Can deploy Pipeline 4 in phases:
  1. Basic pypdf (Week 3)
  2. GROBID integration (Week 4)
  3. Enrichment features (Week 5)

---

## Recommendation: GO AHEAD âœ…

**Why?**
1. Current structure is unmaintainable
2. Pipeline 4 is incomplete and trapped
3. Testing is difficult
4. ChatGPT integration blocked
5. Clean separation is industry best practice

**How?**
- Phased rollout (6 weeks)
- Each phase independently tested
- No breaking changes for users
- Can pause/adjust between phases

**When?**
- Start this week with Pipeline 2 extraction
- Complete by end of November 2025
