# Complete File-Level Migration Strategy

**Date:** October 14, 2025  
**Goal:** Separate OLD vs NEW systems, integrate unified database, archive obsolete code  
**Strategy:** Surgical integration - no risky rewrites, clear migration path

---

## ğŸ“Š COMPLETE FILE INVENTORY

### **ğŸŸ¢ NEW System (Phases 1-5) - KEEP & INTEGRATE**

#### **Phase 1: Unified Database**
```
omics_oracle_v2/lib/storage/
â”œâ”€â”€ unified_db.py              âœ… NEW - UnifiedDatabase class (8 tables)
â”œâ”€â”€ schema.sql                 âœ… NEW - Database schema
â””â”€â”€ models.py                  âœ… NEW - Type-safe dataclasses
```
**Status:** Complete, tested, committed (419d9cb)  
**Action:** âœ… KEEP - Integrate into SearchOrchestrator

---

#### **Phase 2: GEO-Centric Storage**
```
omics_oracle_v2/lib/storage/
â”œâ”€â”€ geo_storage.py             âœ… NEW - GEOStorage class (SHA256, manifests)
â””â”€â”€ integrity.py               âœ… NEW - Integrity verification
```
**Status:** Complete, tested, committed (0e90654)  
**Action:** âœ… KEEP - Integrate into SearchOrchestrator

---

#### **Phase 3: Pipeline Coordinator**
```
omics_oracle_v2/lib/pipelines/
â””â”€â”€ coordinator.py             âœ… NEW - PipelineCoordinator (P1-P4 integration)
```
**Status:** Complete, tested, committed (9f2bddf)  
**Action:** âœ… KEEP - Add to SearchOrchestrator

---

#### **Phase 4: Queries & Analytics**
```
omics_oracle_v2/lib/storage/
â”œâ”€â”€ queries.py                 âœ… NEW - DatabaseQueries (15+ methods)
â””â”€â”€ analytics.py               âœ… NEW - Analytics (10+ methods)
```
**Status:** Complete, tested, committed (7b6dbc3)  
**Action:** âœ… KEEP - Already integrated with UnifiedDatabase

---

#### **Phase 5: Integration Tests**
```
tests/integration/
â””â”€â”€ test_integration_workflow.py  âœ… NEW - End-to-end tests
```
**Status:** Complete, 10/11 passing (f664d5e)  
**Action:** âœ… KEEP - Validates entire system

---

### **ğŸŸ¡ OLD System (Pre-Phase 1) - KEEP BUT ISOLATED**

#### **SQLAlchemy Auth Database (User Management)**
```
omics_oracle_v2/database/
â”œâ”€â”€ __init__.py                ğŸŸ¡ OLD - SQLAlchemy for auth ONLY
â”œâ”€â”€ base.py                    ğŸŸ¡ OLD - SQLAlchemy Base
â”œâ”€â”€ session.py                 ğŸŸ¡ OLD - Async sessions for auth
â””â”€â”€ migrations/                ğŸŸ¡ OLD - Alembic migrations

omics_oracle_v2/auth/
â”œâ”€â”€ models.py                  ğŸŸ¡ OLD - User, APIKey models (SQLAlchemy)
â”œâ”€â”€ crud.py                    ğŸŸ¡ OLD - User CRUD operations
â”œâ”€â”€ security.py                ğŸŸ¡ OLD - Password hashing, JWT
â”œâ”€â”€ quota.py                   ğŸŸ¡ OLD - Rate limiting
â””â”€â”€ schemas.py                 ğŸŸ¡ OLD - Pydantic models for auth
```

**Purpose:** User authentication, API keys, rate limiting  
**Database:** Separate SQLAlchemy async database for users  
**Status:** âœ… WORKING - Handles auth correctly  
**Action:** âœ… **KEEP SEPARATE** - Auth database is independent from search database

**Why Keep Separate?**
- Different concern: Users vs. Search Data
- Different ORM: SQLAlchemy (auth) vs. sqlite3 (search)
- Different tables: `users`, `api_keys` vs. `citations`, `pdfs`, etc.
- Already working: No need to change

**No Conflict:** Auth database and Search database are completely separate!

---

### **ğŸ”´ PROBLEMATIC Code - NEEDS INTEGRATION**

#### **Search Orchestrator (Currently Isolated)**
```
omics_oracle_v2/lib/search_orchestration/
â”œâ”€â”€ orchestrator.py            ğŸ”´ PROBLEM - NO unified database integration
â”œâ”€â”€ config.py                  ğŸŸ¡ NEEDS UPDATE - Add db_path, storage_path
â””â”€â”€ models.py                  âœ… OK - SearchResult models
```

**Current State:**
- âœ… Parallel search (GEO + PubMed + OpenAlex)
- âœ… Redis caching
- âŒ NO UnifiedDatabase
- âŒ NO GEOStorage  
- âŒ NO PipelineCoordinator
- âŒ Results not persisted

**Action Required:**
```python
# orchestrator.py - ADD:
from omics_oracle_v2.lib.pipelines.coordinator import PipelineCoordinator

class SearchOrchestrator:
    def __init__(self, config):
        # ... existing code ...
        
        # ADD: Initialize coordinator for database persistence
        self.coordinator = PipelineCoordinator(
            db_path=config.db_path,
            storage_path=config.storage_path
        )
```

---

#### **Search Clients (Have Bugs)**
```
omics_oracle_v2/lib/search_engines/citations/
â”œâ”€â”€ pubmed.py                  ğŸ”´ BUG - Line 475: await list error
â””â”€â”€ openalex.py                ğŸ”´ BUG - Missing search_publications() method
```

**Action Required:**
- Fix PubMed: Remove `await` (method is synchronous)
- Fix OpenAlex: Use correct method name

---

### **ğŸŸ¢ GOOD Code - ALREADY WORKS**

#### **Search Engines (Work Correctly)**
```
omics_oracle_v2/lib/search_engines/
â”œâ”€â”€ geo/
â”‚   â”œâ”€â”€ client.py              âœ… WORKS - GEO search client
â”‚   â”œâ”€â”€ query_builder.py       âœ… WORKS - GEO query optimization
â”‚   â””â”€â”€ models.py              âœ… WORKS - GEOSeriesMetadata
â””â”€â”€ citations/
    â”œâ”€â”€ pubmed.py              âš ï¸ WORKS but has async bug (fixable)
    â””â”€â”€ openalex.py            âš ï¸ WORKS but has method name bug (fixable)
```

**Action:** Keep, fix bugs only

---

#### **API Routes**
```
omics_oracle_v2/api/routes/
â”œâ”€â”€ agents.py                  ğŸ”´ NEEDS UPDATE - Add database save calls
â”œâ”€â”€ auth.py                    âœ… OK - Uses auth database (separate)
â”œâ”€â”€ users.py                   âœ… OK - Uses auth database (separate)
â”œâ”€â”€ health.py                  âœ… OK - Health checks
â””â”€â”€ metrics.py                 âœ… OK - Prometheus metrics
```

**Action:**
- `agents.py`: Update to save results via PipelineCoordinator
- Others: No changes needed

---

## ğŸ¯ MIGRATION STRATEGY

### **Key Principle: COEXISTENCE, NOT REPLACEMENT**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TWO DATABASES (DIFFERENT PURPOSES)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Database 1: AUTH (SQLAlchemy)         âœ… KEEP AS-IS           â”‚
â”‚  â”œâ”€â”€ omics_oracle.db                                            â”‚
â”‚  â”œâ”€â”€ Tables: users, api_keys                                    â”‚
â”‚  â””â”€â”€ Used by: auth/, api/routes/auth.py, api/routes/users.py   â”‚
â”‚                                                                  â”‚
â”‚  Database 2: SEARCH (sqlite3)          âœ… ADD TO ORCHESTRATOR  â”‚
â”‚  â”œâ”€â”€ data/database/omics_oracle.db                             â”‚
â”‚  â”œâ”€â”€ Tables: citations, urls, pdfs, enriched_content, etc.     â”‚
â”‚  â””â”€â”€ Used by: SearchOrchestrator (NEW), PipelineCoordinator    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**No Conflict!** Two separate databases for two separate concerns.

---

## ğŸ“‹ DETAILED MIGRATION STEPS

### **Step 1: Add Database Config** (5 min)

**File:** `omics_oracle_v2/lib/search_orchestration/config.py`

**Change:**
```python
@dataclass
class SearchConfig:
    # ... existing fields ...
    
    # ADD: Database paths for persistence
    db_path: str = "data/database/search_data.db"  # Search database
    storage_path: str = "data/pdfs"                # PDF storage
```

**Why:** Orchestrator needs to know where to store data

---

### **Step 2: Integrate PipelineCoordinator** (30 min)

**File:** `omics_oracle_v2/lib/search_orchestration/orchestrator.py`

**Changes:**

```python
# ADD import at top:
from omics_oracle_v2.lib.pipelines.coordinator import PipelineCoordinator

class SearchOrchestrator:
    def __init__(self, config: SearchConfig):
        # ... existing code (geo_client, pubmed_client, etc.) ...
        
        # ADD: Initialize pipeline coordinator for database persistence
        logger.info(f"Initializing PipelineCoordinator (db={config.db_path})")
        self.coordinator = PipelineCoordinator(
            db_path=config.db_path,
            storage_path=config.storage_path
        )
        logger.info("PipelineCoordinator initialized successfully")

    async def search(self, query, ...):
        # ... existing search logic ...
        
        # Get results (existing code)
        search_result = SearchResult(...)
        
        # ADD: Save to database AFTER search
        await self._persist_results(search_result)
        
        return search_result
    
    # ADD: New method to save results
    async def _persist_results(self, result: SearchResult) -> None:
        """Save search results to unified database."""
        if not result.geo_datasets:
            return
        
        logger.info(f"Persisting {len(result.geo_datasets)} datasets to database")
        
        for dataset in result.geo_datasets:
            try:
                # P1: Save citation discovery
                if dataset.pubmed_ids:
                    for pmid in dataset.pubmed_ids[:1]:  # Save primary PMID
                        self.coordinator.save_citation_discovery(
                            geo_id=dataset.geo_id,
                            pmid=pmid,
                            citation_data={
                                "title": dataset.title,
                                "summary": dataset.summary,
                                "organism": dataset.organism,
                                "platform": dataset.platforms[0] if dataset.platforms else None,
                                "sample_count": dataset.sample_count,
                                "publication_date": dataset.publication_date,
                            }
                        )
                        logger.debug(f"Saved citation: {dataset.geo_id} -> {pmid}")
            except Exception as e:
                logger.error(f"Failed to save {dataset.geo_id}: {e}")
        
        logger.info("Database persistence complete")
```

**Why:** Connects search results to database without breaking existing functionality

---

### **Step 3: Fix PubMed Client** (5 min)

**File:** `omics_oracle_v2/lib/search_orchestration/orchestrator.py`

**Find line ~475:**
```python
async def _search_pubmed(self, query: str, max_results: int):
    # BEFORE (BROKEN):
    results = await self.pubmed_client.search(query, max_results=max_results)
```

**Replace with:**
```python
async def _search_pubmed(self, query: str, max_results: int):
    # AFTER (FIXED):
    # Run synchronous method in executor to avoid blocking
    loop = asyncio.get_event_loop()
    results = await loop.run_in_executor(
        None,
        self.pubmed_client.search,
        query,
        max_results
    )
```

**Why:** `pubmed_client.search()` is synchronous, can't await it directly

---

### **Step 4: Fix OpenAlex Client** (10 min)

**First, check actual method name:**
```bash
grep -n "def.*search" omics_oracle_v2/lib/search_engines/citations/openalex.py
```

**File:** `omics_oracle_v2/lib/search_orchestration/orchestrator.py`

**Find line ~491:**
```python
async def _search_openalex(self, query: str, max_results: int):
    # BEFORE (BROKEN):
    results = await self.openalex_client.search_publications(query, max_results=max_results)
```

**Replace with (using correct method name):**
```python
async def _search_openalex(self, query: str, max_results: int):
    # AFTER (FIXED - check actual method name):
    results = await self.openalex_client.search(query, max_results=max_results)
    # OR if method is synchronous:
    loop = asyncio.get_event_loop()
    results = await loop.run_in_executor(
        None,
        self.openalex_client.search,
        query,
        max_results
    )
```

**Why:** Method name is incorrect

---

### **Step 5: Fix Resource Leaks** (15 min)

**File:** `omics_oracle_v2/lib/search_orchestration/orchestrator.py`

**Find `close()` method:**
```python
async def close(self):
    """Clean up resources."""
    logger.info("Closing SearchOrchestrator")
    
    # ADD: Close coordinator (cascades to database)
    if hasattr(self, 'coordinator') and self.coordinator:
        try:
            # PipelineCoordinator doesn't have close() yet, but database does
            if hasattr(self.coordinator.db, 'close'):
                self.coordinator.db.close()
            logger.debug("Database closed")
        except Exception as e:
            logger.warning(f"Database close failed: {e}")
    
    # Existing closes...
    if self.geo_client:
        await self.geo_client.close()
    
    if self.cache:
        await self.cache.close()
    
    logger.info("SearchOrchestrator closed")
```

**Why:** Prevents connection leaks

---

### **Step 6: Update API Route** (OPTIONAL - orchestrator handles it)

**File:** `omics_oracle_v2/api/routes/agents.py`

**No changes needed!** SearchOrchestrator now saves automatically.

**BUT** if you want explicit control:
```python
@router.post("/search", ...)
async def execute_search(request: SearchRequest):
    # ... existing code ...
    
    # Search (now saves to DB automatically)
    search_result = await pipeline.search(query=query, ...)
    
    # Optional: Return database IDs in response
    # (for future: allow users to retrieve saved searches)
    
    return SearchResponse(...)
```

---

## ğŸ“¦ WHAT TO ARCHIVE (NOTHING!)

**Critical Decision:** We're NOT archiving anything because there are NO duplicate systems!

### **Why No Archiving Needed:**

1. **Auth Database (SQLAlchemy):** âœ… KEEP
   - Purpose: User management, API keys, rate limiting
   - Location: `omics_oracle_v2/database/`, `omics_oracle_v2/auth/`
   - Action: No changes

2. **Search Database (UnifiedDatabase):** âœ… ADD
   - Purpose: Search results, citations, PDFs, extraction
   - Location: `omics_oracle_v2/lib/storage/unified_db.py`
   - Action: Integrate into orchestrator

3. **SearchOrchestrator:** âœ… ENHANCE
   - Purpose: Coordinate searches
   - Location: `omics_oracle_v2/lib/search_orchestration/`
   - Action: Add database persistence (don't replace!)

**No Parallel Systems!** We're adding persistence to existing search orchestrator.

---

## ğŸ¯ FILE CHANGE SUMMARY

### **Files to Modify (6 files)**

| File | Changes | Lines | Time |
|------|---------|-------|------|
| `search_orchestration/config.py` | Add db_path, storage_path | +2 | 5 min |
| `search_orchestration/orchestrator.py` | Add coordinator, persist method, fix bugs | +50 | 45 min |
| `search_engines/citations/pubmed.py` (or orchestrator) | Fix async issue | -1, +5 | 5 min |
| `search_engines/citations/openalex.py` (or orchestrator) | Fix method name | -1, +1 | 10 min |

**Total:** 4 files, ~58 lines changed, ~65 minutes

---

### **Files to Keep Unchanged (All Others)**

âœ… UnifiedDatabase (lib/storage/unified_db.py)  
âœ… GEOStorage (lib/storage/geo_storage.py)  
âœ… PipelineCoordinator (lib/pipelines/coordinator.py)  
âœ… DatabaseQueries (lib/storage/queries.py)  
âœ… Analytics (lib/storage/analytics.py)  
âœ… Auth system (database/, auth/)  
âœ… API routes (except agents.py if optional changes)  
âœ… All search clients (geo, pubmed, openalex)  

---

## âœ… VALIDATION PLAN

### **After Integration:**

1. **Test Auth Still Works**
   ```bash
   # Login should still work (uses separate auth database)
   curl -X POST http://localhost:8000/api/auth/login \
     -H "Content-Type: application/json" \
     -d '{"email":"test@example.com","password":"test"}'
   ```

2. **Test Search Works**
   ```bash
   # Search and check logs for database saves
   # Frontend: "DNA methylation and brain cancer"
   tail -f logs/omics_api.log | grep "Persisting"
   ```

3. **Verify Database Writes**
   ```bash
   # Check unified database has data
   sqlite3 data/database/search_data.db "SELECT COUNT(*) FROM citations;"
   ```

4. **Test DatabaseQueries**
   ```python
   from omics_oracle_v2.lib.storage.queries import DatabaseQueries
   
   queries = DatabaseQueries("data/database/search_data.db")
   citations = queries.get_citations_for_geo("GSE12345")
   print(f"Found {len(citations)} citations")
   ```

---

## ğŸš€ EXECUTION ORDER

### **Phase A: Quick Wins (30 min)**

1. âœ… Fix PubMed bug (5 min)
2. âœ… Fix OpenAlex bug (10 min)
3. âœ… Fix resource leaks (15 min)
4. âœ… Test frontend search (10 min)

**Checkpoint:** Frontend search works without errors

---

### **Phase B: Database Integration (1 hour)**

1. âœ… Add config fields (5 min)
2. âœ… Add PipelineCoordinator to orchestrator (30 min)
3. âœ… Add _persist_results() method (15 min)
4. âœ… Test database writes (10 min)

**Checkpoint:** Search results persist to database

---

### **Phase C: Validation (30 min)**

1. âœ… Test auth still works (5 min)
2. âœ… Test search + database (10 min)
3. âœ… Query database with DatabaseQueries (10 min)
4. âœ… Check analytics work (5 min)

**Checkpoint:** All systems working together

---

## ğŸ“Š FINAL ARCHITECTURE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend Dashboard                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Routes                                                     â”‚
â”‚  â”œâ”€â†’ /api/auth/*       â†’ Auth Database (SQLAlchemy)           â”‚
â”‚  â””â”€â†’ /api/agents/search â†’ SearchOrchestrator                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SearchOrchestrator (ENHANCED)                                  â”‚
â”‚  â”œâ”€â†’ Parallel Search (GEO + PubMed + OpenAlex)                â”‚
â”‚  â”œâ”€â†’ Redis Caching                                             â”‚
â”‚  â””â”€â†’ PipelineCoordinator (NEW!)                               â”‚
â”‚      â”œâ”€â†’ UnifiedDatabase (8 tables)                           â”‚
â”‚      â””â”€â†’ GEOStorage (SHA256, manifests)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TWO DATABASES (COEXIST)                                        â”‚
â”‚  â”œâ”€â†’ omics_oracle.db (Auth - SQLAlchemy)                      â”‚
â”‚  â””â”€â†’ data/database/search_data.db (Search - sqlite3)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points:**
- âœ… No parallel systems - single enhanced orchestrator
- âœ… Two databases for two purposes (auth vs. search)
- âœ… All Phases 1-5 integrated
- âœ… No old code to archive (auth system stays)
- âœ… Minimal changes (4 files, ~60 minutes)

---

## ğŸ¯ READY TO PROCEED?

**I will:**
1. Make the 4 file changes (surgical, targeted)
2. Test each change incrementally
3. Verify database integration works
4. Then proceed to production validation

**No risky rewrites, no archiving needed - just clean integration!**

Shall I start with Phase A (bug fixes)?
