"""
Integration Test: Pipeline 2 â†’ 3 â†’ 4 Data Flow

Tests the complete pipeline flow from URL collection through PDF download to text enrichment.
Uses real Open Access publications to validate end-to-end functionality.

Pipeline Flow:
    Publication â†’ [P2: URL Collection] â†’ FullTextResult
                      â†“
    FullTextResult â†’ [P3: PDF Download] â†’ DownloadResult
                      â†“
    DownloadResult â†’ [P4: Text Enrichment] â†’ ParsedContent

Test Strategy:
    - Use Open Access papers (reliable, no paywalls)
    - Test each pipeline stage independently
    - Test full end-to-end flow
    - Validate data contracts at each integration point
    - Clean up test files after execution

Author: OmicsOracle Team
Created: October 14, 2025
"""

import asyncio
import logging
import os
from pathlib import Path

import pytest
from dotenv import load_dotenv

from omics_oracle_v2.lib.pipelines.pdf_download import PDFDownloadManager
from omics_oracle_v2.lib.pipelines.text_enrichment import PDFExtractor
from omics_oracle_v2.lib.pipelines.url_collection import FullTextManager, FullTextManagerConfig
from omics_oracle_v2.lib.search_engines.citations.models import Publication, PublicationSource

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)

# Test data directory
TEST_DIR = Path(__file__).parent.parent.parent / "data" / "test_integration"
TEST_PDF_DIR = TEST_DIR / "pdfs"


@pytest.fixture(scope="module")
def test_publications():
    """
    Create test publications (Open Access for reliability).

    Using well-known OA papers:
    1. PLoS ONE paper (PMC available)
    2. Nature Communications paper (OA, PMC available)
    """
    return [
        # PLoS ONE - Highly reliable OA source
        Publication(
            title="A Test Publication from PLoS ONE",
            doi="10.1371/journal.pone.0123456",  # Example DOI pattern
            pmid="25654321",
            journal="PLoS ONE",
            authors=["Smith J", "Jones A"],
            year=2020,
            source=PublicationSource.PUBMED,
        ),
        # Use a real OA paper for actual testing
        Publication(
            title="SARS-CoV-2 Vaccines",
            doi="10.1038/s41586-020-2622-0",  # Real Nature paper (OA)
            pmid="32760000",
            journal="Nature",
            authors=["Multiple Authors"],
            year=2020,
            source=PublicationSource.PUBMED,
        ),
    ]


@pytest.fixture(scope="module")
def setup_test_directory():
    """Ensure test directory exists and is clean."""
    TEST_DIR.mkdir(parents=True, exist_ok=True)
    TEST_PDF_DIR.mkdir(parents=True, exist_ok=True)
    yield TEST_PDF_DIR
    # Cleanup after tests
    # Comment out for debugging: keep files to inspect
    # import shutil
    # shutil.rmtree(TEST_DIR, ignore_errors=True)


class TestPipeline2URLCollection:
    """Test Pipeline 2: URL Collection in isolation."""

    @pytest.mark.asyncio
    async def test_url_collection_initialization(self):
        """Test that URL Collection Manager initializes correctly."""
        manager = FullTextManager()
        await manager.initialize()

        # Verify sources initialized
        assert manager.pmc_client is not None, "PMC client should be initialized"
        assert manager.unpaywall_client is not None, "Unpaywall client should be initialized"
        assert manager.core_client is not None, "CORE client should be initialized"

        logger.info("âœ… Pipeline 2 (URL Collection) initialized successfully")

    @pytest.mark.asyncio
    async def test_url_collection_single_publication(self, test_publications):
        """Test URL collection for a single publication."""
        manager = FullTextManager()
        await manager.initialize()

        publication = test_publications[1]  # Use real Nature paper

        logger.info(f"Testing URL collection for: {publication.title}")
        result = await manager.get_all_fulltext_urls(publication)

        # Validate contract: FullTextResult
        assert result is not None, "Result should not be None"
        assert hasattr(result, "success"), "Result should have 'success' field"
        assert hasattr(result, "all_urls"), "Result should have 'all_urls' field"
        assert hasattr(result, "publication"), "Result should have 'publication' field"

        # Check if URLs were found
        if result.success:
            assert len(result.all_urls) > 0, "Should find at least one URL for OA paper"
            logger.info(f"âœ… Found {len(result.all_urls)} URLs from sources:")
            for url_obj in result.all_urls[:5]:  # Show first 5
                logger.info(f"   - {url_obj.source}: {url_obj.url[:80]}...")
        else:
            logger.warning(f"âš ï¸  No URLs found: {result.error}")
            # For OA papers, we should find URLs - this might indicate API issues
            pytest.skip(f"URL collection failed (API issue?): {result.error}")

    @pytest.mark.asyncio
    async def test_url_collection_batch(self, test_publications):
        """Test batch URL collection."""
        manager = FullTextManager()
        await manager.initialize()

        logger.info(f"Testing batch URL collection for {len(test_publications)} publications")
        results = await manager.get_fulltext_batch(test_publications)

        assert len(results) == len(test_publications), "Should return result for each publication"

        successful = sum(1 for r in results if r.success)
        logger.info(f"âœ… Batch collection: {successful}/{len(test_publications)} successful")

        # For debugging: show what we found
        for i, result in enumerate(results):
            pub = test_publications[i]
            if result.success:
                logger.info(f"   {pub.title[:50]}... â†’ {len(result.all_urls)} URLs")
            else:
                logger.warning(f"   {pub.title[:50]}... â†’ FAILED: {result.error}")


class TestPipeline3PDFDownload:
    """Test Pipeline 3: PDF Download in isolation."""

    @pytest.mark.asyncio
    async def test_pdf_download_with_fallback(self, test_publications, setup_test_directory):
        """Test PDF download with URL fallback strategy."""
        # First, get URLs using Pipeline 2
        url_manager = FullTextManager()
        await url_manager.initialize()

        publication = test_publications[1]  # Real Nature paper
        url_result = await url_manager.get_all_fulltext_urls(publication)

        if not url_result.success or not url_result.all_urls:
            pytest.skip("No URLs available for download test")

        # Now test Pipeline 3
        download_manager = PDFDownloadManager()
        download_result = await download_manager.download_with_fallback(
            publication=publication,
            urls=url_result.all_urls,
            output_dir=setup_test_directory,
        )

        # Validate contract: DownloadResult
        assert download_result is not None, "Result should not be None"
        assert hasattr(download_result, "success"), "Result should have 'success' field"
        assert hasattr(download_result, "pdf_path"), "Result should have 'pdf_path' field"
        assert hasattr(download_result, "publication"), "Result should have 'publication' field"

        if download_result.success:
            assert download_result.pdf_path is not None, "PDF path should be set on success"
            assert download_result.pdf_path.exists(), "PDF file should exist"
            assert download_result.file_size > 0, "PDF should have content"

            logger.info(f"âœ… Downloaded PDF: {download_result.pdf_path.name}")
            logger.info(f"   Size: {download_result.file_size / 1024:.1f}KB")
            logger.info(f"   Source: {download_result.source}")
        else:
            logger.warning(f"âš ï¸  Download failed: {download_result.error}")
            pytest.skip(f"PDF download failed: {download_result.error}")


class TestPipeline4TextEnrichment:
    """Test Pipeline 4: Text Enrichment in isolation."""

    @pytest.mark.asyncio
    async def test_pdf_text_extraction(self, test_publications, setup_test_directory):
        """Test PDF text extraction."""
        # First, get PDF using P2 â†’ P3
        url_manager = FullTextManager()
        await url_manager.initialize()

        publication = test_publications[1]
        url_result = await url_manager.get_all_fulltext_urls(publication)

        if not url_result.success:
            pytest.skip("No URLs for extraction test")

        download_manager = PDFDownloadManager()
        download_result = await download_manager.download_with_fallback(
            publication=publication,
            urls=url_result.all_urls,
            output_dir=setup_test_directory,
        )

        if not download_result.success:
            pytest.skip("No PDF for extraction test")

        # Now test Pipeline 4
        extractor = PDFExtractor()
        parsed_content = extractor.extract_text(download_result.pdf_path)

        # Validate contract: Parsed content
        assert parsed_content is not None, "Parsed content should not be None"
        assert "full_text" in parsed_content, "Should have 'full_text' field"

        if parsed_content.get("full_text"):
            text_length = len(parsed_content["full_text"])
            assert text_length > 100, "Should extract substantial text (>100 chars)"

            logger.info(f"âœ… Extracted text from PDF")
            logger.info(f"   Text length: {text_length} characters")
            logger.info(f"   Preview: {parsed_content['full_text'][:200]}...")
        else:
            pytest.fail("Failed to extract text from PDF")


class TestFullPipelineIntegration:
    """Test complete P2 â†’ P3 â†’ P4 integration."""

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_complete_pipeline_flow(self, test_publications, setup_test_directory):
        """
        Test complete pipeline flow: Publication â†’ URLs â†’ PDF â†’ Text

        This is the critical end-to-end test that validates the entire
        pipeline integration works correctly.
        """
        publication = test_publications[1]  # Real Nature paper

        logger.info("=" * 80)
        logger.info("FULL PIPELINE INTEGRATION TEST")
        logger.info("=" * 80)
        logger.info(f"Publication: {publication.title}")
        logger.info(f"DOI: {publication.doi}")
        logger.info(f"PMID: {publication.pmid}")
        logger.info("-" * 80)

        # ===== STAGE 1: URL Collection (Pipeline 2) =====
        logger.info("\n[STAGE 1/3] URL Collection (Pipeline 2)")

        # Create config with proper API keys from environment
        url_config = FullTextManagerConfig(
            enable_institutional=True,
            enable_pmc=True,
            enable_unpaywall=True,
            enable_core=True,
            enable_biorxiv=True,
            enable_arxiv=True,
            enable_crossref=True,
            core_api_key=os.getenv("CORE_API_KEY"),
            unpaywall_email=os.getenv("NCBI_EMAIL", "sdodl001@odu.edu"),
        )

        url_manager = FullTextManager(config=url_config)
        await url_manager.initialize()

        url_result = await url_manager.get_all_fulltext_urls(publication)

        assert url_result is not None, "P2 should return a result"
        assert url_result.success, f"P2 should succeed for OA paper: {url_result.error}"
        assert len(url_result.all_urls) > 0, "P2 should find URLs for OA paper"

        logger.info(f"âœ… Stage 1 Complete: Found {len(url_result.all_urls)} URLs")
        for i, url_obj in enumerate(url_result.all_urls[:3], 1):
            logger.info(f"   {i}. {url_obj.source}: {url_obj.url[:60]}...")

        # ===== STAGE 2: PDF Download (Pipeline 3) =====
        logger.info("\n[STAGE 2/3] PDF Download (Pipeline 3)")
        download_manager = PDFDownloadManager()

        download_result = await download_manager.download_with_fallback(
            publication=publication,
            all_urls=url_result.all_urls,  # Fixed: parameter name is all_urls, not urls
            output_dir=setup_test_directory,
        )

        assert download_result is not None, "P3 should return a result"
        assert download_result.success, f"P3 should succeed: {download_result.error}"
        assert download_result.pdf_path is not None, "P3 should provide PDF path"
        assert download_result.pdf_path.exists(), "Downloaded PDF should exist"

        logger.info(f"âœ… Stage 2 Complete: Downloaded PDF")
        logger.info(f"   Path: {download_result.pdf_path.name}")
        logger.info(f"   Size: {download_result.file_size / 1024:.1f}KB")
        logger.info(f"   Source: {download_result.source}")

        # ===== STAGE 3: Text Enrichment (Pipeline 4) =====
        logger.info("\n[STAGE 3/3] Text Enrichment (Pipeline 4)")
        extractor = PDFExtractor()

        parsed_content = extractor.extract_text(download_result.pdf_path)

        assert parsed_content is not None, "P4 should return parsed content"
        assert "full_text" in parsed_content, "P4 should extract full text"
        assert len(parsed_content["full_text"]) > 1000, "P4 should extract substantial text"

        text_length = len(parsed_content["full_text"])
        logger.info(f"âœ… Stage 3 Complete: Extracted text")
        logger.info(f"   Text length: {text_length:,} characters")
        logger.info(f"   Preview: {parsed_content['full_text'][:150]}...")

        # ===== FINAL VALIDATION =====
        logger.info("\n" + "=" * 80)
        logger.info("ðŸŽ‰ FULL PIPELINE INTEGRATION TEST PASSED!")
        logger.info("=" * 80)
        logger.info("Pipeline stages validated:")
        logger.info(f"  âœ… P2: URL Collection â†’ {len(url_result.all_urls)} URLs")
        logger.info(f"  âœ… P3: PDF Download â†’ {download_result.file_size / 1024:.1f}KB PDF")
        logger.info(f"  âœ… P4: Text Enrichment â†’ {text_length:,} chars")
        logger.info("=" * 80)

        # Return results for further assertions if needed
        return {
            "url_result": url_result,
            "download_result": download_result,
            "parsed_content": parsed_content,
        }

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_batch_pipeline_flow(self, test_publications, setup_test_directory):
        """Test batch processing through all pipelines."""
        logger.info("\n" + "=" * 80)
        logger.info("BATCH PIPELINE INTEGRATION TEST")
        logger.info("=" * 80)

        # Stage 1: Batch URL Collection
        logger.info("[STAGE 1] Batch URL Collection")
        url_manager = FullTextManager()
        await url_manager.initialize()

        url_results = await url_manager.get_fulltext_batch(test_publications)
        successful_urls = [r for r in url_results if r.success and r.all_urls]

        logger.info(f"âœ… URLs: {len(successful_urls)}/{len(test_publications)} successful")

        if not successful_urls:
            pytest.skip("No URLs found for batch test")

        # Stage 2: Batch PDF Download
        logger.info("[STAGE 2] Batch PDF Download")
        download_manager = PDFDownloadManager()

        download_tasks = [
            download_manager.download_with_fallback(
                publication=url_result.publication,
                urls=url_result.all_urls,
                output_dir=setup_test_directory,
            )
            for url_result in successful_urls
        ]

        download_results = await asyncio.gather(*download_tasks)
        successful_downloads = [r for r in download_results if r.success]

        logger.info(f"âœ… Downloads: {len(successful_downloads)}/{len(successful_urls)} successful")

        if not successful_downloads:
            pytest.skip("No PDFs downloaded for batch test")

        # Stage 3: Batch Text Extraction
        logger.info("[STAGE 3] Batch Text Extraction")
        extractor = PDFExtractor()

        parsed_results = []
        for download_result in successful_downloads:
            try:
                parsed = extractor.extract_text(download_result.pdf_path)
                if parsed and parsed.get("full_text"):
                    parsed_results.append(parsed)
            except Exception as e:
                logger.warning(f"Parse failed: {e}")

        logger.info(f"âœ… Parsed: {len(parsed_results)}/{len(successful_downloads)} successful")

        # Final Report
        logger.info("\n" + "=" * 80)
        logger.info("BATCH PIPELINE SUMMARY")
        logger.info("=" * 80)
        logger.info(f"Input publications: {len(test_publications)}")
        logger.info(
            f"URLs collected: {len(successful_urls)} ({len(successful_urls)/len(test_publications)*100:.0f}%)"
        )
        logger.info(
            f"PDFs downloaded: {len(successful_downloads)} ({len(successful_downloads)/len(successful_urls)*100 if successful_urls else 0:.0f}%)"
        )
        logger.info(
            f"Text extracted: {len(parsed_results)} ({len(parsed_results)/len(successful_downloads)*100 if successful_downloads else 0:.0f}%)"
        )
        logger.info("=" * 80)

        # Assert we got some results
        assert len(parsed_results) > 0, "Should successfully process at least one publication"


if __name__ == "__main__":
    # Run tests with verbose output
    pytest.main([__file__, "-v", "-s", "--log-cli-level=INFO"])
