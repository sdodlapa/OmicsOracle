#!/usr/bin/env python3
"""
GEOCache Validation Script

Tests the new GEOCache system end-to-end by:
1. Generating real data from pipeline
2. Verifying UnifiedDB population
3. Testing cache behavior
4. Running performance benchmarks

Usage:
    python -m scripts.validate_geocache
    python -m scripts.validate_geocache --geo-ids GSE12345,GSE67890
    python -m scripts.validate_geocache --skip-benchmarks
"""

import argparse
import asyncio
import logging
import sys
from pathlib import Path

from omics_oracle_v2.lib.pipelines.storage.unified_db import UnifiedDatabase
from omics_oracle_v2.lib.pipelines.storage.registry.geo_registry import GEORegistry

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def validate_geocache(geo_ids: list[str], skip_benchmarks: bool = False):
    """
    Validate GEOCache system end-to-end.
    
    Args:
        geo_ids: List of GEO IDs to test with
        skip_benchmarks: If True, skip performance benchmarks
    """
    logger.info("=" * 80)
    logger.info("GEOCache Validation")
    logger.info("=" * 80)
    
    # Step 1: Initialize components
    logger.info("\n1. Initializing components...")
    db_path = "data/database/omics_oracle.db"
    unified_db = UnifiedDatabase(db_path)
    registry = GEORegistry()
    
    logger.info(f"‚úÖ UnifiedDatabase: {db_path}")
    logger.info(f"‚úÖ GEORegistry: Initialized with GEOCache")
    
    # Step 2: Check existing data in UnifiedDB
    logger.info("\n2. Checking UnifiedDB for existing data...")
    with unified_db.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM geo_datasets")
        geo_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM universal_identifiers")
        pub_count = cursor.fetchone()[0]
    
    logger.info(f"   GEO datasets: {geo_count}")
    logger.info(f"   Publications: {pub_count}")
    
    if geo_count == 0:
        logger.warning("‚ö†Ô∏è  No GEO datasets found in UnifiedDB!")
        logger.warning("   You need to run the pipeline first to populate data.")
        logger.warning("   Example:")
        logger.warning("     python -m omics_oracle_v2.lib.pipelines.geo_pipeline \\")
        logger.warning("       --geo-ids GSE12345,GSE67890 \\")
        logger.warning("       --query 'cancer immunotherapy'")
        return False
    
    # Step 3: Test cache behavior
    logger.info("\n3. Testing GEOCache behavior...")
    
    # 3a. Test cache miss (should fetch from DB)
    test_geo_id = geo_ids[0] if geo_ids else f"GSE{geo_count}"
    logger.info(f"   Testing cache MISS for {test_geo_id}...")
    
    try:
        data = await registry.get_complete_geo_data(test_geo_id)
        if data:
            logger.info(f"   ‚úÖ Cache miss ‚Üí DB fetch successful")
            logger.info(f"      Title: {data.get('title', 'N/A')[:60]}...")
            logger.info(f"      Publications: {len(data.get('publications', []))}")
        else:
            logger.warning(f"   ‚ö†Ô∏è  No data found for {test_geo_id}")
    except Exception as e:
        logger.error(f"   ‚ùå Failed to fetch {test_geo_id}: {e}")
        return False
    
    # 3b. Test cache hit (should fetch from Redis)
    logger.info(f"\n   Testing cache HIT for {test_geo_id}...")
    try:
        data = await registry.get_complete_geo_data(test_geo_id)
        if data:
            logger.info(f"   ‚úÖ Cache hit ‚Üí Redis fetch successful")
        else:
            logger.warning(f"   ‚ö†Ô∏è  Cache miss (unexpected)")
    except Exception as e:
        logger.error(f"   ‚ùå Failed to fetch from cache: {e}")
        return False
    
    # 3c. Test cache stats
    logger.info("\n   Checking cache statistics...")
    try:
        stats = await registry.get_cache_stats()
        logger.info(f"   ‚úÖ Cache stats:")
        logger.info(f"      Hit rate: {stats.get('hit_rate', 0):.1%}")
        logger.info(f"      Size: {stats.get('size', 0)} entries")
    except Exception as e:
        logger.error(f"   ‚ùå Failed to get cache stats: {e}")
    
    # Step 4: Run benchmarks (optional)
    if not skip_benchmarks:
        logger.info("\n4. Running performance benchmarks...")
        logger.info("   (This may take a few minutes...)")
        
        import subprocess
        result = subprocess.run(
            ["python", "-m", "scripts.benchmark_geocache", "--iterations", "50"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            logger.info("   ‚úÖ Benchmarks completed successfully")
            # Print last 20 lines of output
            for line in result.stdout.split('\n')[-20:]:
                if line.strip():
                    logger.info(f"      {line}")
        else:
            logger.warning("   ‚ö†Ô∏è  Benchmarks failed or did not meet targets")
            logger.warning("      Check data/reports/geocache_benchmark.json for details")
    else:
        logger.info("\n4. Skipping benchmarks (use --run-benchmarks to enable)")
    
    # Step 5: Summary
    logger.info("\n" + "=" * 80)
    logger.info("Validation Summary")
    logger.info("=" * 80)
    logger.info(f"‚úÖ UnifiedDB: {geo_count} GEO datasets, {pub_count} publications")
    logger.info(f"‚úÖ GEOCache: Working (cache hit/miss tested)")
    logger.info(f"‚úÖ GEORegistry: Async API functional")
    if not skip_benchmarks:
        logger.info(f"‚úÖ Benchmarks: Run complete")
    logger.info("=" * 80)
    
    return True


def main():
    """Run validation script."""
    parser = argparse.ArgumentParser(description="Validate GEOCache system")
    parser.add_argument(
        "--geo-ids",
        type=str,
        help="Comma-separated list of GEO IDs to test with"
    )
    parser.add_argument(
        "--skip-benchmarks",
        action="store_true",
        help="Skip performance benchmarks"
    )
    
    args = parser.parse_args()
    
    geo_ids = []
    if args.geo_ids:
        geo_ids = [gid.strip() for gid in args.geo_ids.split(",")]
    
    # Run validation
    success = asyncio.run(validate_geocache(geo_ids, args.skip_benchmarks))
    
    if success:
        logger.info("\nüéâ GEOCache validation successful!")
        return 0
    else:
        logger.error("\n‚ùå GEOCache validation failed!")
        logger.error("   Please populate UnifiedDB first by running the pipeline")
        return 1


if __name__ == "__main__":
    sys.exit(main())
